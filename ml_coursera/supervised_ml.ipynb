{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning: Regression and Classification\n",
    "\n",
    "## Regression\n",
    "\n",
    "### Linear Regression Model\n",
    "\n",
    "#### Univariate Linear Regression\n",
    "\n",
    "Our linear regression model is $ f_{w,b}(x) = wx + b$, and our cost function is \n",
    "$$\n",
    "J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{i}) - y^{i})^{2}.\n",
    "$$\n",
    "\n",
    "We use the gradient descent algorithm as a way to train a regression model. For example, if we have some cost function $ J(w,b) $ for linear regression, we want $\\min_{w,b}  J(w,b)$. We do this through gradient descent. \n",
    "\n",
    "The gradient descent function for a simultaneous update is as follows: \n",
    "$$\n",
    "\\text{Repeat Until Convergence}: \\begin{cases}\n",
    "w = w - \\alpha \\frac{\\partial}{\\partial w} J(w,b) = w - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{i}) - y^{i})x^{i} \\\\\n",
    "b = b - \\alpha \\frac{\\partial}{\\partial b} J(w,b) = b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{i}) - y^{i}) \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "Where $\\alpha$ is the learning rate. \n",
    "- Too small of a learning rate will still work, but gradient descent will be slow.\n",
    "- If $\\alpha$ is too large, gradient descent may fail to converge or could diverge. \n",
    "\n",
    "In **batch** gradient descent, each step of the gradient descent algorithm uses all the training examples. \n",
    "\n",
    "#### Multiple Linear Regression\n",
    "\n",
    "For a problem with multiple feature variables, we need to change our model. For a table with $i$ rows and $j$ feature columns, denote that:\n",
    "- $x_j$ is the $j^{th}$ feature. \n",
    "- $n$ is the number of features.\n",
    "- $\\vec{x}^{(i)}$ is the features of the $i^{th}$ training example. \n",
    "- $x_j^{(i)}$ is the value of feature $j$ in the $i^{th}$ training example. \n",
    "\n",
    "Our linear regression model is now $f_{w,b}(x) = w_1x_1 + w_2x_2 + ... + b$, or in vector notation $f_{\\vec{w},b}(x) = \\vec{w} \\cdot \\vec{x} + b$\n",
    "\n",
    "The cost function now becomes $J(\\vec{w}, b)$ and so our gradient descent algorithm transforms into: \n",
    "$$\n",
    "\\text{Repeat Until Convergence}: \\begin{cases}\n",
    "w_j = w_j - \\alpha \\frac{\\partial}{\\partial w_j} J(\\vec{w},b) = w_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\vec{w},b}(\\vec{x^{i}}) - y^{i}){x_j}^{i} \\\\\n",
    "b = b - \\alpha \\frac{\\partial}{\\partial b} J(\\vec{w},b) = b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\vec{w},b}(\\vec{x^{i}}) - y^{i}) \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "with simultaneous updates to $w_j$ for $j = 1,...,n$ and $b$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "##### Feature Scaling\n",
    "\n",
    "To allow gradient descent to work more efficiently, we can use feature scaling. This is useful for when you have features that take on very different ranges of values. Typically we want to do this so values are $-1 \\le x \\le 1$, but ranges close to this may not need rescaling. We only need to rescale if the values are much larger or much smaller than this range. \n",
    "\n",
    "There are different ways of doing this: \n",
    "* Dividing by the maximum: for a range $ a \\le x \\le b$, we divide by $b$ to get $\\frac{a}{b} \\le x \\le 1$\n",
    "* Mean normalisation: for a range $ a \\le x \\le b$ with a mean value $\\mu$, we normalise $x$ by $x = \\frac{x - \\mu}{b - a}$ so that the new range is $\\frac{a - \\mu}{b - a} \\le x \\le \\frac{b - \\mu}{b - a}$.\n",
    "* Z-score normalisation: for a range $ a \\le x \\le b$ with a mean $\\mu$ and a standard deviation $\\sigma$, we normalise $x$ by $x = \\frac{x - \\mu}{\\sigma}$ so that the new range is $\\frac{a - \\mu}{\\sigma} \\le x \\le \\frac{b - \\mu}{\\sigma}$.\n",
    "\n",
    "###### Convergence\n",
    "\n",
    "Let $\\epsilon \\gg 0$. If $J (\\vec{w},b)$ decreases by $\\le \\epsilon$ in one iteration, declare **convergence**.\n",
    "\n",
    "##### Feature Engineering\n",
    "\n",
    "Feature engineering ivolves using intuition to design new features, by transforming or combining original features. For example, if we have features $x_1,x_2$ then we can create a new feature $x_3 = x_1x_2$.\n",
    "\n",
    "##### Polynomial Regression \n",
    "\n",
    "For non-linear data, you can create polynomial feaures through feature engineering. \n",
    "\n",
    "##### Linear Regression in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import SGDRegressor               #Gradient Descent Regression Model\n",
    "from sklearn.preprocessing import StandardScaler            #Scales the data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification \n",
    "\n",
    "### Logistic Regression \n",
    "\n",
    "As linear regression is not a good algorithm for classification problems, we turn to logistic regression. \n",
    "\n",
    "#### Logistic Regression Model\n",
    "\n",
    "\n",
    "##### Sigmoid Function \n",
    "\n",
    "The sigmoid function (also known as the **logistic function**) outputs values between 0 and 1. The function is as follows: \n",
    "$$\n",
    "g(z) = \\frac{1}{1 + e^{-z}} \\text{ for } 0 \\lt g(z) \\lt 1\n",
    "$$\n",
    "\n",
    "#####  Linear Regression Algorithm\n",
    "\n",
    "Remember that the linear regression algorithm is $ f_{\\vec{w},b} (\\vec{x}) = \\vec{w} \\cdot \\vec{x} + b$\n",
    "\n",
    "##### Building Logistic Regression Algorithm \n",
    "\n",
    "If we let $z = \\vec{w} \\cdot \\vec{x} + b$ and sub $z$ into $g(z)$ we get:\n",
    "$$ \n",
    "f_{\\vec{w},b} (\\vec{x}) = g(z) \n",
    "                        = g(\\vec{w} \\cdot \\vec{x} + b)\n",
    "                        = \\frac{1}{1 + e^{-(\\vec{w} \\cdot \\vec{x} + b)}}\n",
    "$$\n",
    "\n",
    "##### Algorithm Interpretation\n",
    "\n",
    "The result that you get from the algorithm can be interpreted as the \"probability\" that the classification is 1. \n",
    "\n",
    "For example, if we take $x = \\text{tumor size}$ and \n",
    "$y = \\begin{cases}\n",
    "    0 \\text{ : not malignant} \\\\\n",
    "    1 \\text{ : malignant} \\\\\n",
    "\\end{cases}\n",
    "$\n",
    "then $f_{\\vec{w},b} (\\vec{x}) = 0.7$ would mean there is a $70\\%$ chance that $y$ is $1$\n",
    "\n",
    "You can interpret the logistic regression algorithm as $f_{\\vec{w},b} (\\vec{x}) = P(y = 1|\\vec{x};\\vec{w},b)$\n",
    "\n",
    "##### Decision Boundary\n",
    "\n",
    "* A linear decision boundary is when $z = \\vec{w} \\cdot \\vec{x} + b = 0$\n",
    "* A non-linear decision boundary can be different. We can use polynomial regression to fit the decision boundary to our plotted data.\n",
    "\n",
    "##### Cost Function for Logistic Regression\n",
    "\n",
    "Plotting the logistic regression function in the square error cost used in linear regression would result in a non-convex cost function. This means that gradient descent would not work as there would be multiple local minima. Instead, we plot a cost function for logistic regression. \n",
    "\n",
    "Note that the **cost function for linear regression** is \n",
    "$$\n",
    "J(\\vec{w},b) = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{1}{2} (f_{\\vec{w},b} (\\vec{x}^i) - y^i)^2\n",
    "$$ \n",
    "We denote the loss function \n",
    "$$ \n",
    "L(f_{\\vec{w},b} (\\vec{x}^i),y^i) = \\frac{1}{2} (f_{\\vec{w},b} (\\vec{x}^i) - y^i)^2\n",
    "$$ for linear regression. \n",
    "\n",
    "For **logistic regression**, we denote the logistic loss function as: \n",
    "$$\n",
    "L(f_{\\vec{w},b} (\\vec{x}^i),y^i) = \n",
    "\\begin{cases}\n",
    "- log(f_{\\vec{w},b} (\\vec{x}^i)) \\text { if } y^i = 1 \\\\\n",
    "- log (1 - f_{\\vec{w},b} (\\vec{x}^i))) \\text { if } y^i = 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "The further prediction $f_{\\vec{w},b} (\\vec{x}^i)$ is from the target $y^i$, the higher the loss. \n",
    "\n",
    "Hence the **cost function for logistic regression** is \n",
    "$$\n",
    "J(\\vec{w},b) = \\frac{1}{m} \\sum_{i=1}^{m} L(f_{\\vec{w},b} (\\vec{x}^i),y^i) = \n",
    "\\begin{cases}\n",
    "- \\frac{1}{m} \\sum_{i=1}^{m} log(f_{\\vec{w},b} (\\vec{x}^i)) \\text { if } y^i = 1 \\\\\n",
    "- \\frac{1}{m} \\sum_{i=1}^{m} log (1 - f_{\\vec{w},b} (\\vec{x}^i))) \\text { if } y^i = 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We can simply these to get: \n",
    "$$ \n",
    "\\begin{aligned}\n",
    "\\text{Logistic Loss Function } &= L(f_{\\vec{w},b} (\\vec{x}^i),y^i) \\\\\n",
    "&= -y^i log(f_{\\vec{w},b}(x^i)) - (1 - y^i) log (1 - f_{\\vec{w},b}(x^i)) \\\\\n",
    "\\text{Cost Function for Logistic Regression } &= J(\\vec{w},b) \\\\ \n",
    "&= - \\frac{1}{m} \\sum_{i=1}^{m} L(f_{\\vec{w},b} (\\vec{x}^i),y^i) \\\\\n",
    "&= - \\frac{1}{m} \\sum_{i=1}^{m} [-y^i log(f_{\\vec{w},b}(x^i)) - (1 - y^i) log (1 - f_{\\vec{w},b}(x^i))] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "##### Gradient Descent for Logistic Regression\n",
    "\n",
    "Gradient Descent can be used to minimise the cost function. As a reminder the algorithm is: \n",
    "$$\n",
    "\\text{Repeat Until Convergence}: \\begin{cases}\n",
    "w_j = w_j - \\alpha \\frac{\\partial}{\\partial w_j} J(\\vec{w},b) = w_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\vec{w},b}(\\vec{x^{i}}) - y^{i}){x_j}^{i} \\\\\n",
    "b = b - \\alpha \\frac{\\partial}{\\partial b} J(\\vec{w},b) = b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\vec{w},b}(\\vec{x^{i}}) - y^{i}) \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "with simultaneous updates to $w_j$ for $j = 1,...,n$ and $b$ and where \n",
    "$$\n",
    "f_{\\vec{w},b}(\\vec{x}) = \\frac{1}{1 + \\exp^{(-\\vec{w} \\cdot \\vec{x} + b})}\n",
    "$$\n",
    "\n",
    "##### Logistic Regression in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression # Imports Logistic Regression function from sci-kit learn\n",
    "LogisticRegression.fit(X,y)                         # Fits logistic regression model\n",
    "LogisticRegressssion.predict(X)                     # Predicts y based on value x\n",
    "LogisticRegression.score(X,y)                       # Calculates accuracy of the model with a score from 0-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting \n",
    "\n",
    "### The Problem\n",
    "\n",
    "A lot of the time with fitting regression functions to data, we have the problem of overfitting. The types are: \n",
    "* Underfitting - this is when the model does not fit the training set well and the algorithm has high bias. \n",
    "* Overfitting - this is when the model fits the training set extremely well but does not work for generalisation and the algorithm has high variance. Often this means the model will not predict future values accurately. \n",
    "\n",
    "### Addressing Overfitting \n",
    "\n",
    "There are a few ways we can do this:\n",
    "1. Collect more data\n",
    "2. Select features\n",
    "3. Reduce size of parameters through **regularisation**\n",
    "\n",
    "Regularisation involves reducing the size of the parameters $w_j$. We do this by eliminating features from our model or reducing the size of some of the $w_j$ values to allow the curve to fit the pattern. \n",
    "\n",
    "### Cost Function for Regularisation\n",
    "\n",
    "For the cost function for regularisation, we add the regularisation term $\\frac{\\lambda}{2m} \\sum_{j=1}^m w_j^2$ to the original cost function: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Cost Function for Regularisation} &= J(\\vec{w},b) \\\\ \n",
    "&= \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\vec{w},b}(\\vec{x}^i) - y^i)^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2 \\\\\n",
    "&\\text{where } \\lambda \\gt 0 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We want to minimise the original cost (mean squared error cost) and the regularisation term. This helps us to fit the data and keep $w_j$ small. To balance both of these, you pick a suitable value of $\\lambda$.\n",
    "* A large value of $\\lambda$ will reduce the size of parameters $w_1,...,w_n$\n",
    "\n",
    "### Regularised Linear Regression \n",
    "\n",
    "For gradient descent, we know we want to minimise the cost function, i.e. \n",
    "$$\n",
    "\\min_{\\vec{w},b} J(\\vec{w},b) = \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\vec{w},b}(\\vec{x}^i) - y^i)^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2 \n",
    "$$ \n",
    "\n",
    "Apply this to our gradient descent algorithm, we get: \n",
    "$$\n",
    "\\text{Repeat Until Convergence}: \\begin{cases}\n",
    "w = w - \\alpha \\frac{\\partial}{\\partial w} J(\\vec{w},b) = w - \\alpha [ \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{i}) - y^{i})x_j^{i} + \\frac{\\lambda}{m}w_j ] \\\\\n",
    "b = b - \\alpha \\frac{\\partial}{\\partial b} J(\\vec{w},b) = b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{i}) - y^{i}) \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Regularised Logistic Regression\n",
    "\n",
    "For gradient descent, we know we want to minimise the cost function, i.e. \n",
    "$$\n",
    "\\min_{\\vec{w},b} J(\\vec{w},b) = - \\frac{1}{m} \\sum_{i=1}^{m} [-y^i log(f_{\\vec{w},b}(x^i)) - (1 - y^i) log (1 - f_{\\vec{w},b}(x^i))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2 \n",
    "$$\n",
    "where $f_{\\vec{w},b} = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "Apply this to our gradient descent algorithm, we get: \n",
    "$$\n",
    "\\text{Repeat Until Convergence}: \\begin{cases}\n",
    "w = w - \\alpha \\frac{\\partial}{\\partial w} J(\\vec{w},b) = w - \\alpha [ \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{i}) - y^{i})x_j^{i} + \\frac{\\lambda}{m}w_j ] \\\\\n",
    "b = b - \\alpha \\frac{\\partial}{\\partial b} J(\\vec{w},b) = b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_{w,b}(x^{i}) - y^{i}) \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caffff98d144b369287ad0d4368df724c83d5682a99274de39cd1f951c63e42d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
