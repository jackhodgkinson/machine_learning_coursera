{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Learning Algorithms\n",
    "\n",
    "## Neural Networks \n",
    "\n",
    "### Intuition \n",
    "\n",
    "Neural networks are based on the biological neurons and how they are in a network. A neural network in machine learning is based on a simplified mathematical model of a neuron. In a neural network, a **neuron** takes in an input layer $\\vec{x}$ of $x$ features, feeds the input to a **neuron layer** which has $k$ **activations**. A neuron layer are sometimes known as \"hidden layer\" and it is possible for there to be multiple. If there are $l$ layers, the lth layer outputs a vector $\\vec{a}^{[l]}$ of which has $k_l$ activations. The final neuron layer can be used as the input for a second neuron. The output of each layer is used for the next layer. A neural network is a collection of these neurons that are all connected. \n",
    "\n",
    "### The Model\n",
    "\n",
    "To calculate the output vector for a layer $l$, denoted $\\vec{a}^{[l]}$, we use the sigmoid function $$g(z) = \\frac{1}{1 + e^{-z}} = \\frac{1}{1+e^{-(\\vec{w} \\cdot x + b)}}$$ from logistic regression. We call $g(z)$ the **activation function**. For feature $j$ of the output, we use the formula: $$a_j^{[l]} = g(\\vec{w}_j^{[l]} \\cdot \\vec{a}^{[l-1]} + b_j^{[l]})$$ where $a_j^{[l]}$ is the activation value of layer $l$, unit (neuron) $j$. We call the input layer $\\vec{x} = \\vec{a}^{[0]}$.\n",
    "\n",
    "### TensorFlow\n",
    "\n",
    "TensorFlow is one of the leading frameworks for implementing deep learning algorithms. We use TensorFlow to implement inference in code. There are some inconsistencies between Numpy and TensorFlow which we will discuss below. \n",
    "\n",
    "#### Numpy vs TensorFlow \n",
    "\n",
    "* Matrices in Numpy are written as 1D vectors inside an main array, but written row-wise. This results in a 2D array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]] is a 2x3 array\n",
      "[[ 0.1  0.2]\n",
      " [ 0.4 -0.7]\n",
      " [ 5.  -4. ]\n",
      " [ 1.  -0.5]] is a 4x2 array\n",
      "[[200  17]] is a 1x2 array\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "print(x, \"is a 2x3 array\") \n",
    "y = np.array([[0.1,0.2],[0.4,-0.7],[5,-4],[1,-0.5]])\n",
    "print(y, \"is a 4x2 array\")\n",
    "z = np.array([[200,17]])\n",
    "print(z, \"is a 1x2 array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TensorFlow represents the data in matrices instead of arrays. This allows TensorFlow to be more computationally efficient. \n",
    "* You can convert Numpy arrays to TensorFlow Matrices and vice versa as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.1  0.2]\n",
      " [ 0.4 -0.7]\n",
      " [ 5.  -4. ]\n",
      " [ 1.  -0.5]], shape=(4, 2), dtype=float64)\n",
      "[[ 0.1  0.2]\n",
      " [ 0.4 -0.7]\n",
      " [ 5.  -4. ]\n",
      " [ 1.  -0.5]] is a 4x2 array\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "a = tf.constant(y)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b, \"is a 4x2 array\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful Functions \n",
    "* **tf.Dense** allows you to create fully connected layers, in which every output depends on every input.\n",
    "* **tf.Sequential** allows you to automatically connect the layers of your neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example \n",
    "\n",
    "If we want to find out if coffee beans are good or bad from data on the roasting temperature (celsius) and duration (minutes) of coffee roasting to produce the best coffee, we can use a machine learning algorithm and TensorFlow to do this through a neural network. We have data on 4 different temperatures and 4 different durations alongside if the coffee beans were good or bad. Let's see if we can predict if the beans are good or bad (i.e. $\\hat{y} \\ge 0.5$ if good and if bad $\\hat{y} \\lt 0.5$))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[200.0, 17.0],\n",
    "              [120.0,5.0],\n",
    "              [425.0,20.0],\n",
    "              [212.0,18.0]])\n",
    "y = np.array([1,0,0,1])\n",
    "model = Sequential([\n",
    "    Dense(units=3, activation='sigmoid'), \n",
    "    Dense(units=1, activation='sigmoid')])                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation \n",
    "\n",
    "To understand how TensorFlow works on neural networks, we will look at how to implement forward propogation in Python. We will use our coffee roasting model from the example above. Below I will show the Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "x = np.array([200, 17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function **dense** to complete one stage of forward propagation in a neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(a_in, W, b):\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):\n",
    "        w = W[:,j]\n",
    "        z = np.dot(w, a_in) + b[j]\n",
    "        a_out[j] = sigmoid(z)\n",
    "    return a_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a function **sequential** which will complete all the stages of forward propagation needed for our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential(x):\n",
    "    a1 = dense(x,W1,b1)\n",
    "    a2 = dense(a1,W2,b2)\n",
    "    a3 = dense(a2,W3,b3)\n",
    "    a4 = dense(a3,W4,b4)\n",
    "    f_x = a4\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation \n",
    "\n",
    "We can simplify our neural network code greatly through vectorisation. This involves us using matrices for simpler code, and utilising matrix multiplication and its rules. I will demonstrate the simplified code below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[200,17]])\n",
    "W = np.array([[1,-3,5],[-2,4,-6]])\n",
    "B = np.array([[-1, 1, 2]])\n",
    "def dense(A_in,W,B):\n",
    "    Z = np.matmul(A_in, W) + B \n",
    "    A_out = sigmoid(Z)\n",
    "    return A_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "If we are given a set of $(x,y)$ examples, how do we build and train a neural network? The steps to train a neural network are as follows: \n",
    "1. Specifiy how to compute output given input $x$ and parameters $w,b$ (define model) -$ f_{\\vec{w},b}(\\vec{x})=\\text{?}$. We do this through a TensorFlow model as shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential([\n",
    "    Dense(units=25, activation='sigmoid'),\n",
    "    Dense(units=15, activation='sigmoid'),\n",
    "    Dense(units=1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Specify the loss function $L(f_{\\vec{w},b}(\\vec{x}),y)$ and cost function $J(\\vec{w},b) = \\frac{1}{m} \\sum_{i=1}^{m} L(f_{\\vec{w},b}(\\vec{x^{(i)}}),y^{(i)})$. In a neural network, we can choose the loss function that we use to compile the model. In this case, we will use the **binary cross entropy** loss function $L(f(\\vec{x}),y) = -y\\log{f(\\vec{x})}-(1-y)\\log{(1-f(\\vec{x}))}$ as we are looking at a binary classifaction problem. The compile function minimises the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "model.compile(loss=BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a regression model, you can use the **mean squared error** loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError \n",
    "model.compile(loss=MeanSquaredError())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We want to train our data to minimise the cost function, i.e. $\\min{J (\\vec{w},b)}$. In a neural network, we want to do this through fitting the model using gradient descent. To recall, this is done by the following algorithm:\n",
    "$$\n",
    "\\text{Repeat Until Convergence}: \\begin{cases}\n",
    "w_j^{[l]} = w_j^{[l]} - \\alpha \\frac{\\partial}{\\partial w _j} J(w,b) \\\\\n",
    "b_j^{[l]} = b_j^{[l]} - \\alpha \\frac{\\partial}{\\partial b_j} J(w,b)  \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "In Python, we refer to the number of steps of gradient descent as **epochs**. For this model, we will do 100 steps. The **fit** function performs gradient descent on the model using back propagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "So far, we have used the **sigmoid** activation function as we have been building our neural networks by taking lots of logistic regression units and stringing them together. However, a neural network can become much more powerful if you choose to use an alternative activation function. We will discuss the most common below:\n",
    "\n",
    "* **Rectified Linaer Unit**, or **ReLU** - $g(z) = \\max{(0,z)}$\n",
    "* **Linear Activation Function** - $g(z) = z$\n",
    "\n",
    "Choosing an activation function for the output layer is normally quite straight forward based on the output values. \n",
    "\n",
    "* A binary classification problem lends itself to using the **sigmoid** activation function, as we want to output and predict the probability that $y=1$. \n",
    "* If we have a regression problem where output $y$ can either be positive or negative, a **linear activation function** would be best.\n",
    "* A regression problem where output $y \\ge 0$ naturally leans towards using the **ReLU** activation function. \n",
    "\n",
    "For the hidden layers, choosing the activation function can be a bit more difficult. The most common choice is the **ReLU** function, as it is allows the neural network to train faster than the sigmoid function and only goes \"flat\" in one place, i.e. when $y<0$. ReLU activation enablse models to stitch together linear segments to model complex non-linear functions. \n",
    "\n",
    "Taking this into account, we can update our model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=15, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we chose all the activation functions in our model to be linear activation functions, we would just have a linear regression, so building a neural network would be pointless. If all the hidden layers used linear activation functions and the output layer used the sigmoid function, we would just hae a logistic regression problem. Therefore, we should only use linaer activation functions in our output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification \n",
    "\n",
    "A multiclass classification problem is where there can be more than $2$ possible output labels. In other words, our target $y$ can take on more than $2$ possible values. Examples of this could be:\n",
    "* Classification of a patient's disease\n",
    "* Visual defect inspection of manufactured goods\n",
    "\n",
    "In a multiclass classification, we are not able to fit a linear model. Instead, we use **Softmax regression**.\n",
    "\n",
    "#### Softmax Regression\n",
    "\n",
    "The Softmax regression algorithm is a generalisation of logistic regression to the multiclass classification context. In general when we have $n$ possible outputs: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\text{For } 0 \\lt i \\lt n \\text{, Our output } a_i = \\mathrm{P}(y=i \\mid \\vec{x}) = \\frac{e^{z_i}}{\\sum_{k=1}^{n} e^{z_k}} \\text{ where } z_{i} = \\vec{w_i} \\cdot \\vec{x} + b_i \\text{ and } \\sum_{i=1}^{n} a_i = 1 \\\\ \n",
    "& \\text{The loss function } loss(\\vec{a},y) = -\\log{a_i} \\text{ if } y=i \\text{ which is } \\textbf{cross-entropy loss} \\\\\n",
    "& \\text{The cost function } J(\\vec{w},b) = \\text{ average loss}\n",
    "\\end{aligned} \n",
    "$$\n",
    "\n",
    "If you want the output of your neural network to have more than 2 output units, we use Softmax regression to produce the output layer. We can use Softmax too in a Tensorflow model, as seen below:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=15, activation='relu'),\n",
    "    Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using Binary Cross Entropy for the loss function, for a multiclass classification problem we use **Sparse Catagorical Cross entropy**. In TensorFlow: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "model.compile(loss=SparseCategoricalCrossentropy())\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this Python code will work for a multiclass classification problem, there is a better and preferred version to use. There is a more numerically accurate implementation of the loss function that reduces the numerical roundoff errors, allowing for more accurate computation. This is done by writing the activation function fully into the loss function. For example: \n",
    "$$\n",
    "L(\\vec{a},y) = -\\log{\\frac{e^{z_i}}{\\sum_{k=1}^{n} e^{z_k}}} \\text{ if } y=i\n",
    "$$\n",
    "You can do this in TensorFlow by having the output layer use the **linear activation function** and by setting the **from_logits=True** option in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=15, activation='relu'),\n",
    "    Dense(units=10, activation='linear'),\n",
    "])\n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Optimisation\n",
    "\n",
    "There are additional optimisation algorithms to minimise the cost function that are even better than gradient descent. Gradient descent is not the most efficient optimisation algorithm for minimising the cost function for a neural network. Instead, we will look at the **Adaptive Moment estimation (Adam) algorithm**.\n",
    "\n",
    "#### Adam Algorithm\n",
    "\n",
    "The Adam algorithm automatically adjusts the learning rate $\\alpha$ to more efficiently minimise the cost function. Instead of using one $\\alpha$ like we do in gradient descent, the Adam algorithm uses a different learning rate for each model parameter. For example: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{For } 10 \\text{ features, we have: } & w_1 = w_1 - \\alpha{_1} \\frac{\\partial}{\\partial w_1} J(\\vec{w},b) \\\\\n",
    "& \\vdots \\\\\n",
    "& w_{10} = w_{10} - \\alpha{_{10}} \\frac{\\partial}{\\partial w_{10}} J(\\vec{w},b) \\\\\n",
    "& b = b - \\alpha{_11} \\frac{\\partial}{\\partial b} J(\\vec{w},b)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* If $w_j$ (or $b$) keeps moving in the same direction, we increase $\\alpha_{j}$.\n",
    "* If $w_j$ (or $b$) keeps oscillating, we reduce $\\alpha_{j}$.\n",
    "\n",
    "In Python, we make a slight update to use TensorFlow. We add in which optimiser we want to use, and it's learning rate. I have picked $\\alpha = 10^{-3}$ for this example, but it is worth trying out a few different learning rates until you reach the fastest performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(units=25, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=15, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=10, activation='linear')\n",
    "    ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Layer Types\n",
    "\n",
    "With a dense layer, each neuron output is a function of all the activation outputs of the previous layer, i.e. $\\vec{a_1}^{[2]} = g(\\vec{w_1}^{[2]} \\cdot \\vec{a}^{[1]} + b_1^{[2]})$. For some applications, it may be better to use a different type of layer such as a **Convolutional Layer**.\n",
    "\n",
    "#### Convolutional Layer\n",
    "\n",
    "This is where each neuron only looks at a part of the previous layer's inputs. This results in faster computation, requires less training data and so is less prone to overfitting. \n",
    "\n",
    "## The Application of Machine Learning\n",
    "\n",
    "### Model Performance Evaluation \n",
    "\n",
    "Having a systematic way to evaluate performance will help to paint a clearer path on how to improve the model's performance. \n",
    "\n",
    "For example, if your model fits the training data well but fails to generalise to new examples not in the training set, one could split the training data into subsets: a training set and a test set. It is reccomended that the training set is the majority of the data. By doing this, you train your model using your training set and test the model's accuracy using your test set. \n",
    "\n",
    "Denote:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& m_{train} = \\text{ number of training examples and } (x^{m_{train}}, y^{m_{train}}) \\text{ as a training example.} \\\\\n",
    "& m_{test} = \\text{ number of test examples and } (x_{test}^{(m_{test})},y_{test}^{(m_{test})}) \\text{ as a test example.} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "#### Linear Regression\n",
    "*To train and evaluate a model using linear regresssion (with squared error cost):*\n",
    "* Fit parameters by minimising cost function $$J(\\vec{w},b) = \\bigg[ \\frac{1}{2m_{train}} \\sum_{i=1}^{m_{train}} (f_{\\vec{w},b}(\\vec{x}^{(i)})-y^{(i)})^2 + \\frac{\\lambda}{2m_{train}} \\sum_{j=1}^{n} w_j^2 \\bigg]$$\n",
    "* Compute Test Error: $$J_{test}(\\vec{w},b) = \\frac{1}{2m_{test}} \\bigg[ \\sum_{i=1}^{m_{test}} (f_{\\vec{w},b}(\\vec{x}_{test}^{(i)})-y_{test}^{(i)})^2 \\bigg]$$\n",
    "* Compute Training Error $$J_{train}(\\vec{w},b) = \\frac{1}{2m_{train}} \\bigg[ \\sum_{i=1}^{m_{train}} (f_{\\vec{w},b}(\\vec{x}_{train}^{(i)})-y_{train}^{(i)})^2 \\bigg]$$\n",
    "\n",
    "As in statistics, we want our error terms to be minimised. Therefore, looking at the test and training error can be a good way to see if our data is sufficient enough to build a machine learning model. \n",
    "\n",
    "#### Classification\n",
    "*To train and evalaute a model for a classification problem:*\n",
    "* Fit parameters by minimising cost function $$J(\\vec{w},b) =  -\\frac{1}{m_{train}} \\sum_{i=1}^{m_{train}} \\bigg[ y^{(i)} \\log{(f_{\\vec{w},b}(\\vec{x}^{(i)}))} + (1-y^{i}) \\log{(1-f_{\\vec{w},b}(\\vec{x}^{(i)}))} \\bigg] + \\frac{\\lambda}{2m_{train}} \\sum_{j=1}^{n} w_j^2$$\n",
    "* Compute Test Error: $$J_{test}(\\vec{w},b) =  -\\frac{1}{m_{test}} \\sum_{i=1}^{m_{test}} \\bigg[ y^{(i)}_{test} \\log{(f_{\\vec{w},b}(\\vec{x}^{(i)}_{test}))} + (1-y^{i}_{test}) \\log{(1-f_{\\vec{w},b}(\\vec{x}^{(i)}_{test}))} \\bigg]$$\n",
    "* Compute Training Error: $$J_{train}(\\vec{w},b) =  -\\frac{1}{m_{train}} \\sum_{i=1}^{m_{train}} \\bigg[ y^{(i)}_{train} \\log{(f_{\\vec{w},b}(\\vec{x}^{(i)}_{train}))} + (1-y^{i}_{train}) \\log{(1-f_{\\vec{w},b}(\\vec{x}^{(i)}_{train}))} \\bigg]$$\n",
    "* Another way we can do this is by measuring the **fraction of the test set** that the algorithm has **misclassified**: $$ \\hat{y} = \\begin{cases} 1 \\text{ if } f_{\\vec{w},b}(\\vec{x}^{(i)}) \\ge 0.5 \\\\ 0 \\text{ if } f_{\\vec{w},b}(\\vec{x}^{(i)}) \\lt 0.5 \\\\ \\end{cases} $$ count $\\hat{y} \\ne y$. We have $J_{test}(\\vec{w},b)$ as the fraction of the test set that has been misclassified and $J_{train}(\\vec{w},b)$ as the fraction of the training set that has been misclassified.\n",
    "\n",
    "*Note: $J_{test}(\\vec{w},b)$ is a better estimate of how well the model will generalise to new data compared to $J_{train}(\\vec{w},b)$*\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "It can be difficult to know which model to choose for your machine learning algorithm. One way we can simplify this is through the addition of cross validation..\n",
    "\n",
    "Now we split our training data into three subsets: a training set, validation set and test set. Denote: \n",
    "Denote:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& m_{train} = \\text{ number of training examples and } (x^{m_{train}}, y^{m_{train}}) \\text{ as a training example.} \\\\\n",
    "& m_{cv} = \\text{ number of validaton examples and } (x^{(m_{cv})}_{cv}, y^{(m_{cv})}_{cv}) \\text{ as a validation example.} \\\\\n",
    "& m_{test} = \\text{ number of test examples and } (x_{test}^{(m_{test})},y_{test}^{(m_{test})}) \\text{ as a test example.} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Linear Regression\n",
    "As before, we can compute the training/cross validation/test errors, with the cross validation error being: $$J_{cv}(\\vec{w},b) = \\frac{1}{2m_{cv}} \\bigg[ \\sum_{i=1}^{m_{cv}} (f_{\\vec{w},b}(\\vec{x}_{cv}^{(i)})-y_{cv}^{(i)})^2 \\bigg]$$ \n",
    "\n",
    "So how do we use the cross validation error to select a model? If we had 10 models: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "1. f_{\\vec{w},b}(\\vec{x}) & = w_1x+b \\\\\n",
    "2. f_{\\vec{w},b}(\\vec{x}) & = w_1x+w_2x^2 + b \\\\\n",
    "   & \\vdots \\\\\n",
    "n. f_{\\vec{w},b}(\\vec{x}) & = w_1x+w_2x^2 + ... + w_nx^n + b \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Then we would take each pair $w^{<n>},b^{<n>}$ and sub them into the cross validation error. The model with the lowest cross validation error is the model that we choose for our machine learning algorithm.\n",
    "\n",
    "#### Choosing a Neural Network Architecture\n",
    "We can use cross validation to decide how many layers our neural network should have, and how many hidden units each layer should have. If we had n neural networks, if we train each model to get our $w^{<n>},b^{<n>}$ then we can choose our model based on measuring the fraction of the validation set that the algorithm has misclassified. \n",
    "\n",
    "### Bias and Variance \n",
    "\n",
    "You can use the cost function as a way to diagnose if your algorithm has a bias or variance problem. \n",
    "* If there is high bias / model underfits then $J_{train}$ will be high i.e. $J_{train} \\approx J_{cv}$.\n",
    "* If there is high variance / model overfits then $J_{train}$ may be high i.e. $J_{train} \\ll J_{cv}$.\n",
    "* If there is high bias and high variance then  $J_{train}$ will be high i.e. $J_{train} \\ll J_{cv}$.\n",
    "\n",
    "### Regularisation \n",
    "\n",
    "To get around the problems of high bias and variance, we need to choose an optimal regularisation parameter $\\lambda$. To do this we: \n",
    "1. Choose a value of $\\lambda$\n",
    "2. Minimise the cost function to get $w^{<n>},b^{<n>}$\n",
    "3. Use $w^{<n>},b^{<n>}$ to calculate the cross validation error $J_{cv}(w^{<n>},b^{<n>})$\n",
    "4. The $\\lambda$ that gives the smallest cross validation error is the optimal $\\lambda$.\n",
    "5. To report out generalisation error, you sub in your $w^{<n>},b^{<n>}$ values that gave optimal $\\lambda$ and calculate the test error $J_{test}(w^{<n>},b^{<n>})$\n",
    "\n",
    "### Learning Curves\n",
    "\n",
    "Learning curves are a way to help understand how the learning algorithm is doing as a function with how many training examples it has. We do this by plotting both $J_{train}$ and $J_{cv}$ on a graph as below: \n",
    "\n",
    "Note: Top curve represents $J_{cv}(\\vec{w},b)$ and bottom curve represents $J_{train}(\\vec{w},b)$\n",
    "\n",
    "![Learning Curves 1](https://www.dataquest.io/wp-content/uploads/2019/01/add_data.png)\n",
    "\n",
    "![Learning Curves 2](https://www.dataquest.io/wp-content/uploads/2019/01/low_high_bias.png)\n",
    "\n",
    "![Learning Curves 3](https://www.dataquest.io/wp-content/uploads/2019/01/low_high_bias.png)\n",
    "\n",
    "### Debugging a Learning Example \n",
    "\n",
    "If your learning algorithm is producing unacceptably large prediction errors, what could you try next? \n",
    "\n",
    "To fix problems with high variance, one could:\n",
    "1. Get more training examples\n",
    "2. Try smaller sets of features\n",
    "3. Try increasing $\\lambda$\n",
    "\n",
    "To fix problems with high bias, one could: \n",
    "1. Try getting additional features\n",
    "2. Try additional polynomial features \n",
    "3. Try decreasing $\\lambda$\n",
    "\n",
    "### Bias and Variance in Neural Networks \n",
    "\n",
    "It turns out that large neural networks when trained on small/moderate sized datasets are low bias machines. This can be dependent on the chosen value of the regularisation parameter $\\lambda$, or the amount of data that the algorithm trains on. \n",
    "\n",
    "To regularise a neural network in TensorFlow, you add in the **kernel_regularizer** option into the Dense layer. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layer_1 = Dense(units=25, activation='relu', kernel_regularizer=L2(0.01)),\n",
    "    layer_2 = Dense(units=15, activation='relu', kernel_regularizer=L2(0.01)),\n",
    "    layer_3 = Dense(units=1, activation='sigmoid', kernel_regularizer=L2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Development Process\n",
    "\n",
    "### The Iterative Loop \n",
    "\n",
    "The process of developing a machine learning algorithm can be defined as a iterative loop which follows the below steps:\n",
    "\n",
    "1. Choose architecture (model, data, etc.)\n",
    "2. Train the model \n",
    "3. Diagnostics (bias, variance and error analysis)\n",
    "4. **Back to Step 1**\n",
    "\n",
    "### Error Analysis \n",
    "\n",
    "The error analysis process involves looking through misclassified features from your algorithm and categorising them based on common traits in the errors. From this, you can see what feature issues are common and the ones you should watch out for. Error analysis helps to understand what changes to the algorithm's architecture are needed. \n",
    "\n",
    "### Adding Data\n",
    "\n",
    "If we are faced with a problem of high bias or variance, a tempting solution to solve this could be to add more data of everything. However, collecting data of all different types can be slow and expensive. Some alternative approaches we could use to add data include: \n",
    "* Only add data of the types where error analysis has indicated that it could help. \n",
    "* Data Augmentation - this involves modifying an existing training example to create a new training example. This could be done by distorting the data slightly but not significantly to help the algorithm recognise its features. \n",
    "\n",
    "### Transfer Learning \n",
    "\n",
    "Transfer learning involves using data from a different task on your machine learning algorithm. \n",
    "\n",
    "For example with a neural network, one may train their algorithm using another neural network's output layer parameters (called **fine tuning**), or train all of the other neural network's parameters on its neural network (called **supervised pretraining**). \n",
    "\n",
    "In summary: \n",
    "1. Download neural network parameters pretrained on a large dataset with the same input type as your application (or train your own)\n",
    "2. Fine tune the network on your own data\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "### The Model \n",
    "\n",
    "A decision tree follows a structure of branches and nodes. The following key terms help with understanding a decision tree: \n",
    "* Root node: The base of the decision tree.\n",
    "* Splitting: The process of dividing a node into multiple sub-nodes.\n",
    "* Decision node: When a sub-node is further split into additional sub-nodes.\n",
    "* Leaf node: When a sub-node does not further split into additional sub-nodes; represents possible outcomes.\n",
    "* Pruning: The process of removing sub-nodes of a decision tree.\n",
    "* Branch: A subsection of the decision tree consisting of multiple nodes.\n",
    "\n",
    "A decision tree may follow a similar structure to the below tree, which predicts scores for a golfer: \n",
    "\n",
    "![Decision Tree](https://www.mastersindatascience.org/wp-content/uploads/sites/54/2022/05/tree-graphic.jpg)\n",
    "\n",
    "### Decision Tree Learning \n",
    "\n",
    "#### Learning Process\n",
    "\n",
    "Given a training set of n examples, we need to follow a process of learning for our decision tree: \n",
    "1. How to choose what features to split on at each node to maximise purity/minimsie inpurity. \n",
    "2. When to stop splitting? \n",
    "   * When a node is 100% of one class\n",
    "   * When splitting a node will result in the tree exceeding a maximum depth\n",
    "   * When improvements in purity score are below a threshold.\n",
    "   * When number of examples in a node is below a threshold. \n",
    "\n",
    "#### Measuring Purity\n",
    "\n",
    "We can use **entropy** as a way to measure impurity in our decision tree. \n",
    "\n",
    "Say we have a classification problem with n classes, $c_n$ and $c_2$. Let $p_n$ be the fraction of examples that are class $c_n$.\n",
    "\n",
    "Entropy of class $c_n$ is denoted as $H(p_n) = -p_n \\log_{2}(p_n) - (1-p_n) \\log_{2}(1-p_n)$. We use $\\log_{2}$ to get the peak of the function to be at when $H(p_n)=1$.\n",
    "\n",
    "#### Choosing a split: Information Gain\n",
    "\n",
    "When we are faced with choices of which feature to split on, we calculate the Information Gain.\n",
    "\n",
    "Information Gain is a measure of how much information a feature provides about a class. It helps to determine the order of attributes in the nodes of a decision tree.\n",
    "\n",
    "Let: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "& p_1^{root} = \\text{ the fraction of examples that are positive in the root node.} \\\\\n",
    "& H(p_i) = \\text{ the entropy calculated based on the probability of a category} p_i \\\\\n",
    "& p_1^{left} = \\text{ the fraction of examples that are class } c_1 \\text{ that went to left sub-branch.} \\\\\n",
    "& p_1^{right} = \\text{ the fraction of examples that are class } c_1 \\text{ that went to right sub-branch.} \\\\\n",
    "& w^{left} = \\text{ the fraction of the examples from the root node that went to the left sub-branch.} \\\\\n",
    "& w^{right} = \\text{ the fraction of the examples from the root node that went to the right sub-branch.} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We calculate the Information Gain $IG$ as:\n",
    "$$\n",
    "IG = H(p_1^{root})-(w^{left} H(p_1^{left}) + w^{right} H(p_1^{right})\n",
    "$$\n",
    "\n",
    "We choose the decision with the highest information gain to split on, i.e. $\\max(IG)$\n",
    "\n",
    "#### Final Process\n",
    "\n",
    "1. Start with all examples at the root node\n",
    "2. Calculate information gain for all posible features, and pick the feature with the highest information gain. \n",
    "3. Split dataset according to selected feature, and create left and right branhces of the tree. \n",
    "4. Keep repeating the splitting process until the stopping criteria is met: \n",
    "    * When a node is 100% one class.\n",
    "    * When splitting a node will result in the tree exceeding a maximum depth. \n",
    "    * Information gain from additional splits is less than threshold. \n",
    "    * When number of examples in a node is below a threshold. \n",
    "\n",
    "#### One-Hot Encoding of Categorical Variables\n",
    "\n",
    "One Hot Encoding is when if a categorical feature can take on $k$ values, then create $k$ binary features (0 or 1 valued). This can be used not only for decision trees, but also for neural networks. \n",
    "\n",
    "#### Continuous Valued Features\n",
    "\n",
    "To get a decision tree to use a continuous valued feature, you choose a constraint to split the feature into two classes. To decide on the constraint, you calculate the information gain based on multiple constraints and go with the constraint with the maximum information gain. \n",
    "\n",
    "### Tree Ensembles\n",
    "\n",
    "#### Multiple Decision Trees\n",
    "\n",
    "A weakness of using a single decision tree is that the decision tree can be highly sensitive to small changes in the data. A solution to this is to build multiple decision trees. This is called a **tree ensemble**.\n",
    "\n",
    "Using multiple decision trees allows you to capture any loopholes in the trees. For your classification, you go with the most popular outcome from each decision tree. \n",
    "\n",
    "#### Random Forest Algorithm \n",
    "\n",
    "The Random Forest algorithm is much more effective than using a single decision tree. Random Forests involve using sampling by replacement to create alternative training sets. \n",
    "\n",
    "Given a training set $t_1$ of size $m$, for $b=1$ to $B$, you can use sampling with replacement to create a new training set $t_2$ of size $m$ and train a decision tree on the new data set $t_2$. We repeat this until we have a decision tree trained on the data set $t_B$, i.e. a total of $B$ times. \n",
    "\n",
    "It is reccomended that $B$ is large, but not too large as too large of a $B$ can result in diminishing returns from the algorithm. It is reccomended that $B \\le 100$.\n",
    "\n",
    "To ensure that we do not have the same feature at the root node, we need to randomise the feature choice. At each node, when choosing a feature to use to split, if $n$ features are available, pick a random subset of $k < n$ features and allow the algorithm to only choose from that subset of features. A typical choice for the value of $k$ when $n$ is large is $k = \\sqrt{n}$.\n",
    "\n",
    "#### XGBoost\n",
    "\n",
    "The most common use of decision tree ensembles is using a boosted decision tree ensemble. \n",
    "\n",
    "This is similar to a Random Forest, but with a slight modification as seen below: \n",
    "- Given a training set of size $m$, for $b=1$ to $B$: \n",
    "  - Use sampling with replacement to create a new training set of size $m$. Instead of picking from all examples with equal $\\frac{1}{m}$ probability, make it more likely to pick misclassified examples from previously trained trees. \n",
    "- Train a decision tree on the new dataset. \n",
    "\n",
    "**XGBoost (eXtreme Gradient Boosting)** is an open source implementation of boosted trees that is fast and efficient. XGBoost provides a good choice of default splitting criteria and criteria for when to stop splitting. Also, it has built in regularisation to prevent overfitting. \n",
    "\n",
    "How to apply XGBoost for a classification problem in Python can be seen below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model=XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use XGBoost for a regression problem by using: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor()\n",
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees vs Neural Networks\n",
    "\n",
    "* Decision Trees and Tree Ensembles: \n",
    "  * Work well on tabular (structured) data\n",
    "  * Not reccomended for unstructured data (images, audio, text)\n",
    "  * Fast to train\n",
    "  * Small decision trees may be human interpretable\n",
    "* Neural Networks: \n",
    "  * Works well on all types of data, including tabular (structured), unstructured and mixed data. \n",
    "  * May be slower than a decision tree\n",
    "  * Works with transfer learning\n",
    "  * When building a system of multiple models working together, it may be easier to string together multiple neural networks. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caffff98d144b369287ad0d4368df724c83d5682a99274de39cd1f951c63e42d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
